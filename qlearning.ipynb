{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354b061b",
   "metadata": {},
   "source": [
    "IMPORT ALL THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9705e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487d401",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79affbe6",
   "metadata": {},
   "source": [
    "DEFINE THE ENVIRONEMENT AND AGENT ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de57fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100. -100. -100. -100. -100. -100. -100. -100.  100. -100. -100. -100.\n",
      " -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.\n",
      "   -1.   -1.   -1.   -1. -100.]\n",
      "[-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100. -100.\n",
      " -100. -100. -100.   -1. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100. -100.\n",
      " -100. -100. -100.   -1. -100.]\n",
      "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100. -100.\n",
      " -100.   -1. -100. -100. -100.]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.   -1.\n",
      " -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.\n",
      "   -1.   -1.   -1.   -1. -100.]\n",
      "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100. -100.\n",
      " -100.   -1. -100. -100. -100.]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.   -1.\n",
      " -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.\n",
      "   -1.   -1.   -1.   -1. -100.]\n",
      "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100. -100.\n",
      " -100.   -1. -100. -100. -100.]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.   -1.\n",
      " -100. -100. -100. -100. -100.]\n",
      "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.\n",
      "   -1.   -1.   -1.   -1. -100.]\n",
      "[-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n",
      " -100. -100. -100. -100. -100.]\n"
     ]
    }
   ],
   "source": [
    "environment_rows = 17\n",
    "environment_columns = 17\n",
    "\n",
    "q_values = np.zeros((environment_rows, environment_columns, 4))\n",
    "\n",
    "#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n",
    "actions = ['up', 'right', 'down', 'left']\n",
    "\n",
    "rewards = np.full((17, 17), -100.)\n",
    "\n",
    "# Set the reward for the packaging area (i.e., the goal) to 100\n",
    "rewards[0, 8] = 100.\n",
    "\n",
    "# Define aisle locations (i.e., white squares) for rows 1 through 15\n",
    "aisles = {}\n",
    "\n",
    "aisles[1] = [i for i in range(1, 16)]\n",
    "aisles[2] = [1, 7, 9, 15]\n",
    "aisles[3] = [i for i in range(1, 8)]\n",
    "aisles[3].append(9)\n",
    "aisles[3].append(15)\n",
    "aisles[4] = [3, 7, 13]\n",
    "aisles[5] = [i for i in range(17)]\n",
    "aisles[6] = [5, 11]\n",
    "aisles[7] = [i for i in range(1, 16)]\n",
    "aisles[8] = [3, 7, 13]\n",
    "aisles[9] = [i for i in range(17)]\n",
    "aisles[10] = [5, 11]\n",
    "aisles[11] = [i for i in range(1, 16)]\n",
    "aisles[12] = [3, 7, 13]\n",
    "aisles[13] = [i for i in range(17)]\n",
    "aisles[14] = [5, 11]\n",
    "aisles[15] = [i for i in range(1, 16)]\n",
    "\n",
    "# Set the rewards for all aisle locations (i.e., white squares)\n",
    "for row_index in range(1, 16):\n",
    "  for column_index in aisles[row_index]:\n",
    "    rewards[row_index, column_index] = -1.\n",
    "  \n",
    "for row in rewards:\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd5eaa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e24cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e5da2f",
   "metadata": {},
   "source": [
    "VISULAIZE THE PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852cbf6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dc1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cmap_custom = plt.cm.colors.ListedColormap(['red', 'yellow', 'blue'])\n",
    "bounds_custom = [-200, -50, 0, 50, 100, 200]  # set color boundaries\n",
    "norm_custom = plt.Normalize(bounds_custom[0], bounds_custom[-1])\n",
    "\n",
    "# Plot the rewards matrix\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(rewards, cmap=cmap_custom, norm=norm_custom)\n",
    "for i in range(rewards.shape[0]):\n",
    "    for j in range(rewards.shape[1]):\n",
    "        reward_value = rewards[i, j]\n",
    "        color_index = np.searchsorted(bounds_custom, reward_value) - 1\n",
    "        color = cmap_custom(norm_custom(color_index))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c5f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a78c745",
   "metadata": {},
   "source": [
    "TERMINAL STATE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c931f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that determines if the specified location is a terminal state\n",
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "  #if the reward for this location is -1, then it is not a terminal state (i.e., it is a 'white square')\n",
    "  if rewards[current_row_index, current_column_index] == -1.:\n",
    "    return False\n",
    "  else:\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fbe5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccfe4f93",
   "metadata": {},
   "source": [
    "STARTING LOCATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c4ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that will choose a random, non-terminal starting location\n",
    "def get_starting_location():\n",
    "  \n",
    "  current_row_index = np.random.randint(environment_rows)\n",
    "  current_column_index = np.random.randint(environment_columns)\n",
    "  \n",
    "  while is_terminal_state(current_row_index, current_column_index):\n",
    "    current_row_index = np.random.randint(environment_rows)\n",
    "    current_column_index = np.random.randint(environment_columns)\n",
    "    \n",
    "    \n",
    "  return current_row_index, current_column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7076f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5ff06c",
   "metadata": {},
   "source": [
    "EPSILON GREEDY ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2fd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an epsilon greedy algorithm that will choose which action to take next (i.e., where to move next)\n",
    "def get_next_action(current_row_index, current_column_index, epsilon):\n",
    "  #if a randomly chosen value between 0 and 1 is less than epsilon, \n",
    "  #then choose the most promising value from the Q-table for this state.\n",
    "  if np.random.random() < epsilon:\n",
    "    return np.argmax(q_values[current_row_index, current_column_index])\n",
    "  else: #choose a random action\n",
    "    return np.random.randint(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee456590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "147a6f59",
   "metadata": {},
   "source": [
    "DEFINE DIFFERENT POSSIBLE ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796664d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that will get the next location based on the chosen action\n",
    "def get_next_location(current_row_index, current_column_index, action_index):\n",
    "  new_row_index = current_row_index\n",
    "  new_column_index = current_column_index\n",
    "  if actions[action_index] == 'up' and current_row_index > 0:\n",
    "    new_row_index -= 1\n",
    "  elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n",
    "    new_column_index += 1\n",
    "  elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n",
    "    new_row_index += 1\n",
    "  elif actions[action_index] == 'left' and current_column_index > 0:\n",
    "    new_column_index -= 1\n",
    "  return new_row_index, new_column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280223a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fec2a400",
   "metadata": {},
   "source": [
    "SHORTEST PATH FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffad7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path(start_row_index, start_column_index):\n",
    "  #return immediately if this is an invalid starting location\n",
    "  if is_terminal_state(start_row_index, start_column_index):\n",
    "    return []\n",
    "  else: #if this is a 'legal' starting location\n",
    "    current_row_index, current_column_index = start_row_index, start_column_index\n",
    "    shortest_path = []\n",
    "    shortest_path.append([current_row_index, current_column_index])\n",
    "    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
    "    while not is_terminal_state(current_row_index, current_column_index):\n",
    "      #get the best action to take\n",
    "      action_index = get_next_action(current_row_index, current_column_index, 1.)\n",
    "      #move to the next location on the path, and add the new location to the list\n",
    "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
    "      shortest_path.append([current_row_index, current_column_index])\n",
    "    return shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815503f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc020520",
   "metadata": {},
   "source": [
    "TRAIN THE AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c5ceb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#define training parameters\n",
    "epsilon = 0.9 #the percentage of time when we should take the best action (instead of a random action)\n",
    "discount_factor = 0.9 #discount factor for future rewards\n",
    "learning_rate = 0.9 #the rate at which the AI agent should learn\n",
    "\n",
    "#run through 1000 training episodes\n",
    "for episode in range(1000):\n",
    "  #get the starting location for this episode\n",
    "  row_index, column_index = get_starting_location()\n",
    "\n",
    "  #continue taking actions (i.e., moving) until we reach a terminal state\n",
    "  #(i.e., until we reach the item packaging area or crash into an item storage location)\n",
    "  while not is_terminal_state(row_index, column_index):\n",
    "    #choose which action to take (i.e., where to move next)\n",
    "    action_index = get_next_action(row_index, column_index, epsilon)\n",
    "\n",
    "    #perform the chosen action, and transition to the next state (i.e., move to the next location)\n",
    "    old_row_index, old_column_index = row_index, column_index \n",
    "    row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
    "    \n",
    "    #receive the reward for moving to the new state, and calculate the temporal difference\n",
    "    reward = rewards[row_index, column_index]\n",
    "    old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
    "    temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
    "\n",
    "    #update the Q-value for the previous state and action pair\n",
    "    new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
    "    q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
    "\n",
    "print('\\nTraining complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e83c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bdc4bd4",
   "metadata": {},
   "source": [
    "TESTING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c17fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 9], [2, 9], [1, 9], [1, 8], [0, 8]]\n",
      "[[5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [4, 7], [3, 7], [2, 7], [1, 7], [1, 8], [0, 8]]\n",
      "[[9, 5], [9, 6], [9, 7], [8, 7], [7, 7], [7, 6], [7, 5], [6, 5], [5, 5], [5, 6], [5, 7], [4, 7], [3, 7], [2, 7], [1, 7], [1, 8], [0, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(get_shortest_path(3, 9)) #starting at row 3, column 9\n",
    "print(get_shortest_path(5, 0)) #starting at row 5, column 0\n",
    "print(get_shortest_path(9, 5)) #starting at row 9, column 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60ec4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffe62686",
   "metadata": {},
   "source": [
    "AGENT RETURNS BACK TO STARTING LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6128b4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 8], [1, 8], [1, 9], [2, 9], [3, 9]]\n"
     ]
    }
   ],
   "source": [
    "path = get_shortest_path(3, 9) #go to row 5, column 2\n",
    "path.reverse()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fe48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
